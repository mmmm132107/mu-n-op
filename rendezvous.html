<!DOCTYPE html>
<html lang="vi">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Voice Debug ‚Äî rendezvous</title>

<style>
body{
  margin:0;
  background:#05070c;
  color:#f3e8dc;
  font-family:system-ui,-apple-system,Segoe UI;
}

.wrap{
  max-width:900px;
  margin:60px auto;
  padding:0 18px;
}

button{
  padding:12px 18px;
  border-radius:12px;
  border:1px solid #d8c8b8;
  background:#16161c;
  color:#f3e8dc;
  cursor:pointer;
}
button:hover{transform:scale(1.02);}

#status{
  margin-top:14px;
  padding:10px 12px;
  border-radius:10px;
  background:#101219;
  min-height:54px;
  font-size:14px;
  line-height:1.6;
  white-space:pre-line;
}

.live{
  margin-top:16px;
  padding:12px;
  border-radius:10px;
  background:#0a0b12;
  font-family:monospace;
  font-size:14px;
  min-height:90px;
}

.log{
  margin-top:18px;
  padding:12px;
  border-radius:10px;
  background:#0c0d13;
  font-family:monospace;
  font-size:13px;
  max-height:260px;
  overflow-y:auto;
}
</style>
</head>

<body>

<div class="wrap">

<h2>Ki·ªÉm tra h·ªá th·ªëng c√≥ nh·∫≠n gi·ªçng n√≥i hay kh√¥ng</h2>

<button id="listenBtn">B·∫Øt ƒë·∫ßu nghe</button>

<div id="status"></div>

<div class="live" id="liveBox">ƒêang ch·ªù t√≠n hi·ªáu‚Ä¶</div>

<div class="log" id="logBox"></div>

</div>

<script>
const statusBox = document.getElementById("status");
const liveBox   = document.getElementById("liveBox");
const logBox    = document.getElementById("logBox");
const listenBtn = document.getElementById("listenBtn");

function log(msg){
  console.log(msg);
  logBox.textContent += msg + "\n";
  logBox.scrollTop = logBox.scrollHeight;
}

/* ====== KH·ªûI T·∫†O SPEECH API ====== */

const SpeechRecognition =
  window.SpeechRecognition || window.webkitSpeechRecognition;

if(!SpeechRecognition){
  statusBox.textContent =
    "‚ö† Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ SpeechRecognition.\n" +
    "H√£y d√πng Chrome ho·∫∑c Edge.";
  log("SpeechRecognition NOT SUPPORTED");
}

const rec = new SpeechRecognition();

/* c·∫•u h√¨nh ƒë·ªÉ h·∫°n ch·∫ø l·ªói NO-SPEECH */
rec.lang = "en-US";          // ·ªïn ƒë·ªãnh nh·∫•t ƒë·ªÉ test
rec.interimResults = true;   // nh·∫≠n k·∫øt qu·∫£ t·∫°m th·ªùi
rec.continuous = true;       // kh√¥ng t·ª± d·ª´ng s·ªõm
rec.maxAlternatives = 1;

let buffer = "";

/* ====== EVENT DEBUG ====== */

rec.onstart = () => {
  statusBox.textContent = "üé§ ƒêang nghe ‚Äî h√£y n√≥i r√µ 2‚Äì3 gi√¢y";
  log("onstart ‚úì recognition started");
};

rec.onaudiostart = () => log("onaudiostart ‚úì mic nh·∫≠n √¢m thanh");
rec.onsoundstart = () => log("onsoundstart ‚úì c√≥ t√≠n hi·ªáu √¢m thanh");
rec.onspeechstart = () => log("onspeechstart ‚úì ph√°t hi·ªán gi·ªçng n√≥i");
rec.onspeechend = () => log("onspeechend ‚Äî t·∫°m d·ª´ng c√¢u n√≥i");
rec.onaudioend = () => log("onaudioend ‚Äî k·∫øt th√∫c chunk audio");

rec.onend = () => {
  log("onend ‚Äî phi√™n nghe k·∫øt th√∫c (t·ª± kh·ªüi ƒë·ªông l·∫°i)");
  rec.start(); // gi·ªØ phi√™n nghe ho·∫°t ƒë·ªông li√™n t·ª•c
};

rec.onnomatch = () => {
  statusBox.textContent = "‚ùì Kh√¥ng hi·ªÉu c√¢u n√≥i";
  log("onnomatch ‚Äî no match");
};

rec.onerror = (e) => {
  statusBox.textContent = "‚õî L·ªói: " + e.error;
  log("ERROR ‚Üí " + e.error);
};

/* ====== NH·∫¨N TEXT REALTIME ====== */

rec.onresult = (e) => {

  const idx = e.resultIndex;
  const spoken = e.results[idx][0].transcript;

  buffer += " " + spoken;

  liveBox.textContent =
    "Gi·ªçng n√≥i ƒëang nh·∫≠n ƒë∆∞·ª£c (live):\n" + buffer.trim();

  statusBox.textContent =
    "‚úì Web ƒë√£ nh·∫≠n ƒë∆∞·ª£c gi·ªçng n√≥i";

  log(`RESULT: "${spoken}"`);
};

/* ====== N√öT B·∫ÆT ƒê·∫¶U ====== */

listenBtn.onclick = () => {
  log("\n\n=== CLICK: START LISTENING ===");
  buffer = "";
  liveBox.textContent = "ƒêang nghe‚Ä¶ n√≥i th·ª≠: ‚Äúhello test one two‚Äù";
  statusBox.textContent = "‚è≥ ƒêang kh·ªüi ƒë·ªông microphone‚Ä¶";
  rec.start();
};
</script>

</body>
</html>

